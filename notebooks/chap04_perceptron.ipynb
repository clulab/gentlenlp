{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f20b9c",
   "metadata": {},
   "source": [
    "# Binary Text Classification with Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d561a30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# set this variable to a number to be used as the random seed\n",
    "# or to None if you don't want to set a random seed\n",
    "seed = 1234\n",
    "\n",
    "if seed is not None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29307e",
   "metadata": {},
   "source": [
    "The dataset is divided in two directories called `train` and `test`.\n",
    "These directories contain the training and testing splits of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb4d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3432\n",
      "-rw-r--r--@ 1 msurdeanu  staff   826K Sep 19  2022 imdb.vocab\n",
      "-rw-r--r--@ 1 msurdeanu  staff   882K Sep 19  2022 imdbEr.txt\n",
      "-rw-r--r--@ 1 msurdeanu  staff   3.9K Sep 19  2022 README\n",
      "drwxr-xr-x@ 8 msurdeanu  staff   256B Mar 17 17:01 \u001b[34mtest\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 8 msurdeanu  staff   256B Mar 17 17:01 \u001b[34mtrain\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/aclImdb/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b7f0b",
   "metadata": {},
   "source": [
    "Both the `train` and `test` directories contain two directories called `pos` and `neg` that contain text files with the positive and negative reviews, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cb65f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 43464\n",
      "-rw-r--r--@     1 msurdeanu  staff    20M Sep 19  2022 labeledBow.feat\n",
      "drwxr-xr-x@ 12502 msurdeanu  staff   391K Sep 19  2022 \u001b[34mneg\u001b[m\u001b[m\n",
      "drwxr-xr-x@ 12502 msurdeanu  staff   391K Sep 19  2022 \u001b[34mpos\u001b[m\u001b[m\n",
      "-rw-r--r--@     1 msurdeanu  staff   598K Sep 19  2022 urls_neg.txt\n",
      "-rw-r--r--@     1 msurdeanu  staff   598K Sep 19  2022 urls_pos.txt\n"
     ]
    }
   ],
   "source": [
    "!ls -lh data/aclImdb/train/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a08c1e",
   "metadata": {},
   "source": [
    "We will now read the filenames of the positive and negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63aeacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positive reviews: 12500\n",
      "number of negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "pos_files = glob('data/aclImdb/train/pos/*.txt')\n",
    "neg_files = glob('data/aclImdb/train/neg/*.txt')\n",
    "\n",
    "print('number of positive reviews:', len(pos_files))\n",
    "print('number of negative reviews:', len(neg_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efbe4f5",
   "metadata": {},
   "source": [
    "Now, we will use a [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) to read the text files, tokenize them, acquire a vocabulary from the training data, and encode it in a document-term matrix in which each row represents a review, and each column represents a term in the vocabulary. Each element $(i,j)$ in the matrix represents the number of times term $j$ appears in example $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c4c300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3445861 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# initialize CountVectorizer indicating that we will give it a list of filenames that have to be read\n",
    "cv = CountVectorizer(input='filename')\n",
    "\n",
    "# learn vocabulary and return sparse document-term matrix\n",
    "doc_term_matrix = cv.fit_transform(pos_files + neg_files)\n",
    "doc_term_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275f5bf3",
   "metadata": {},
   "source": [
    "Note in the message printed above that the matrix is of shape (25000, 74894).\n",
    "In other words, it has 1,871,225,000 elements.\n",
    "However, only 3,445,861 elements were stored.\n",
    "This is because most of the elements in the matrix are zeros.\n",
    "The reason is that the reviews are short and most words in the english language don't appear in each review.\n",
    "A matrix that only stores non-zero values is called *sparse*.\n",
    "\n",
    "Now we will convert it to a dense numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2f3029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 74849)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = doc_term_matrix.toarray()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225d694",
   "metadata": {},
   "source": [
    "We will also create a numpy array with the binary labels for the reviews.\n",
    "One indicates a positive review and zero a negative review.\n",
    "The label `y_train[i]` corresponds to the review encoded in row `i` of the `X_train` matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110f877e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training labels\n",
    "y_pos = np.ones(len(pos_files))\n",
    "y_neg = np.zeros(len(neg_files))\n",
    "y_train = np.concatenate([y_pos, y_neg])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf297533",
   "metadata": {},
   "source": [
    "Now we will initialize our model, in the form of an array of weights `w` of the same size as the number of features in our dataset (i.e., the number of words in the vocabulary acquired by [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)), and a bias term `b`.\n",
    "Both are initialized to zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f99550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model: the feature vector and bias term are populated with zeros\n",
    "n_examples, n_features = X_train.shape\n",
    "w = np.zeros(n_features)\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f466a2",
   "metadata": {},
   "source": [
    "Now we will use the perceptron learning algorithm to learn the values of `w` and `b` from our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a2ef78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c296988696e14c07afa322ee78103c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 1:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89ae29a7f534df6a72c6c1149df28d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 2:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d4ad1a803140e5bdd409e8fb4b1450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 3:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c06f8b46fe4d1b8b5a290978be9395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 4:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae19cc80fadd4e0fa440a554f79d75df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 5:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1aac3ec75694b28a3bac35a2fdc9e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 6:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef90439986af403e847d89ef65d10a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 7:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a392dde89e4e5d95b869292cc4a075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 8:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f4a07fe40864bc092dc08516d15deb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 9:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7011381d5b6640e382e19a19bfd3318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 10:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "indices = np.arange(n_examples)\n",
    "for epoch in range(n_epochs):\n",
    "    n_errors = 0\n",
    "    # randomize the order in which training examples are seen in this epoch\n",
    "    np.random.shuffle(indices)\n",
    "    # traverse the training data\n",
    "    for i in tqdm(indices, desc=f'epoch {epoch+1}'):\n",
    "        x = X_train[i]\n",
    "        y_true = y_train[i]\n",
    "        # the perceptron decision based on the current model\n",
    "        score = x @ w + b\n",
    "        y_pred = 1 if score > 0 else 0\n",
    "        # update the model is the prediction was incorrect\n",
    "        if y_true == y_pred:\n",
    "            continue\n",
    "        elif y_true == 1 and y_pred == 0:\n",
    "            w = w + x\n",
    "            b = b + 1\n",
    "            n_errors += 1\n",
    "        elif y_true == 0 and y_pred == 1:\n",
    "            w = w - x\n",
    "            b = b - 1\n",
    "            n_errors += 1\n",
    "    if n_errors == 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cb18aa",
   "metadata": {},
   "source": [
    "The next step is evaluating the model on the test dataset.\n",
    "Note that this time we use the [`transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.transform) method of the [`CountVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), instead of the [`fit_transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform) method that we used above. This is because we want to use the learned vocabulary in the test set, instead of learning a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56fdb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = glob('data/aclImdb/test/pos/*.txt')\n",
    "neg_files = glob('data/aclImdb/test/neg/*.txt')\n",
    "doc_term_matrix = cv.transform(pos_files + neg_files)\n",
    "X_test = doc_term_matrix.toarray()\n",
    "y_pos = np.ones(len(pos_files))\n",
    "y_neg = np.zeros(len(neg_files))\n",
    "y_test = np.concatenate([y_pos, y_neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c578ae75",
   "metadata": {},
   "source": [
    "Using the model is easy: multiply the document-term matrix by the learned weights and add the bias.\n",
    "We use Python's `@` operator to perform the matrix-vector multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b081198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (X_test @ w + b) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af8d8bc",
   "metadata": {},
   "source": [
    "Now we print an evaluation of the prediction results using scikit-learn's [`classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11822495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_classification_report(y_true, y_pred):\n",
    "    # count true positives, false positives, true negatives, and false negatives\n",
    "    tp = fp = tn = fn = 0\n",
    "    for gold, pred in zip(y_true, y_pred):\n",
    "        if pred == True:\n",
    "            if gold == True:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if gold == False:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "    # calculate precision and recall\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    # calculate f1 score\n",
    "    fscore = 2 * precision * recall / (precision + recall)\n",
    "    # calculate accuracy\n",
    "    accuracy = (tp + tn) / len(y_true)\n",
    "    # number of positive labels in y_true\n",
    "    support = sum(y_true)\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1-score\": fscore,\n",
    "        \"support\": support,\n",
    "        \"accuracy\": accuracy,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9f53d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.9507438971544129,\n",
       " 'recall': 0.52656,\n",
       " 'f1-score': 0.6777531792205118,\n",
       " 'support': 12500.0,\n",
       " 'accuracy': 0.74964}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2958bf9-3e68-47e6-b2a6-e1ce12a4b670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
