{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c031b5",
   "metadata": {},
   "source": [
    "# Text Classification Using Transformer Networks (BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40bd59e",
   "metadata": {},
   "source": [
    "Some initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3afe3bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3441f3",
   "metadata": {},
   "source": [
    "Read the train/dev/test datasets and create a HuggingFace `Dataset` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1885c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    # read csv file\n",
    "    df = pd.read_csv(filename, header=None)\n",
    "    # add column names\n",
    "    df.columns = ['label', 'title', 'description']\n",
    "    # make labels zero-based\n",
    "    df['label'] -= 1\n",
    "    # concatenate title and description, and remove backslashes\n",
    "    df['text'] = df['title'] + \" \" + df['description']\n",
    "    df['text'] = df['text'].str.replace('\\\\', ' ', regex=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03f51a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>0</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>1</td>\n",
       "      <td>Renteria signing a top-shelf deal</td>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "      <td>Renteria signing a top-shelf deal Red Sox gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>1</td>\n",
       "      <td>Saban not going to Dolphins yet</td>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "      <td>Saban not going to Dolphins yet The Miami Dolp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>1</td>\n",
       "      <td>Today's NFL games</td>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "      <td>Today's NFL games PITTSBURGH at NY GIANTS Time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>1</td>\n",
       "      <td>Nets get Carter from Raptors</td>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "      <td>Nets get Carter from Raptors INDIANAPOLIS -- A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                              title  \\\n",
       "0           2  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1           2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2           2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3           2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4           2  Oil prices soar to all-time record, posing new...   \n",
       "...       ...                                                ...   \n",
       "119995      0  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
       "119996      1                  Renteria signing a top-shelf deal   \n",
       "119997      1                    Saban not going to Dolphins yet   \n",
       "119998      1                                  Today's NFL games   \n",
       "119999      1                       Nets get Carter from Raptors   \n",
       "\n",
       "                                              description  \\\n",
       "0       Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1       Reuters - Private investment firm Carlyle Grou...   \n",
       "2       Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3       Reuters - Authorities have halted oil export\\f...   \n",
       "4       AFP - Tearaway world oil prices, toppling reco...   \n",
       "...                                                   ...   \n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...   \n",
       "119996  Red Sox general manager Theo Epstein acknowled...   \n",
       "119997  The Miami Dolphins will put their courtship of...   \n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...   \n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...   \n",
       "\n",
       "                                                     text  \n",
       "0       Wall St. Bears Claw Back Into the Black (Reute...  \n",
       "1       Carlyle Looks Toward Commercial Aerospace (Reu...  \n",
       "2       Oil and Economy Cloud Stocks' Outlook (Reuters...  \n",
       "3       Iraq Halts Oil Exports from Main Southern Pipe...  \n",
       "4       Oil prices soar to all-time record, posing new...  \n",
       "...                                                   ...  \n",
       "119995  Pakistan's Musharraf Says Won't Quit as Army C...  \n",
       "119996  Renteria signing a top-shelf deal Red Sox gene...  \n",
       "119997  Saban not going to Dolphins yet The Miami Dolp...  \n",
       "119998  Today's NFL games PITTSBURGH at NY GIANTS Time...  \n",
       "119999  Nets get Carter from Raptors INDIANAPOLIS -- A...  \n",
       "\n",
       "[120000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = open('data/ag_news_csv/classes.txt').read().splitlines()\n",
    "train_df = read_data('data/ag_news_csv/train.csv')\n",
    "test_df = read_data('data/ag_news_csv/test.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7518aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train rows: 108,000\n",
      "eval rows: 12,000\n",
      "test rows: 7,600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_df = train_test_split(train_df, train_size=0.9)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "eval_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f'train rows: {len(train_df.index):,}')\n",
    "print(f'eval rows: {len(eval_df.index):,}')\n",
    "print(f'test rows: {len(test_df.index):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e06f040b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'title', 'description', 'text'],\n",
       "        num_rows: 108000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'title', 'description', 'text'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'title', 'description', 'text'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "ds = DatasetDict()\n",
    "ds['train'] = Dataset.from_pandas(train_df)\n",
    "ds['validation'] = Dataset.from_pandas(eval_df)\n",
    "ds['test'] = Dataset.from_pandas(test_df)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac23185a",
   "metadata": {},
   "source": [
    "Tokenize the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e8d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "transformer_name = 'bert-base-cased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52a2caf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226324a366f54a4f9936dd0b8e2ac2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5b99bfeb934feb81d46a6468cc5fd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 3270, 11906, 1522, 1146, 7106, 1111, 251...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 4222, 11404, 1174, 117, 1476, 1130, 2696...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 158, 119, 156, 119, 12068, 5084, 1116, 9...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 22087, 8223, 1611, 1106, 4417, 5572, 324...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 7270, 118, 2733, 1383, 1111, 12448, 7430...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107995</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 6096, 117, 10378, 3969, 5977, 1111, 8988...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107996</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 16409, 118, 16587, 159, 4064, 1106, 1564...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107997</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 19569, 5480, 10582, 2087, 1867, 158, 119...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107998</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 11560, 3881, 108, 3614, 132, 3498, 2944,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107999</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 1130, 139, 24683, 131, 21107, 2050, 1739...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                          input_ids  \\\n",
       "0           3  [101, 3270, 11906, 1522, 1146, 7106, 1111, 251...   \n",
       "1           0  [101, 4222, 11404, 1174, 117, 1476, 1130, 2696...   \n",
       "2           0  [101, 158, 119, 156, 119, 12068, 5084, 1116, 9...   \n",
       "3           2  [101, 22087, 8223, 1611, 1106, 4417, 5572, 324...   \n",
       "4           0  [101, 7270, 118, 2733, 1383, 1111, 12448, 7430...   \n",
       "...       ...                                                ...   \n",
       "107995      0  [101, 6096, 117, 10378, 3969, 5977, 1111, 8988...   \n",
       "107996      0  [101, 16409, 118, 16587, 159, 4064, 1106, 1564...   \n",
       "107997      0  [101, 19569, 5480, 10582, 2087, 1867, 158, 119...   \n",
       "107998      0  [101, 11560, 3881, 108, 3614, 132, 3498, 2944,...   \n",
       "107999      3  [101, 1130, 139, 24683, 131, 21107, 2050, 1739...   \n",
       "\n",
       "                                           token_type_ids  \\\n",
       "0       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                   ...   \n",
       "107995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "107996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "107997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "107998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "107999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           attention_mask  \n",
       "0       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                   ...  \n",
       "107995  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "107996  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "107997  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "107998  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "107999  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[108000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['text'], truncation=True)\n",
    "\n",
    "train_ds = ds['train'].map(\n",
    "    tokenize, batched=True,\n",
    "    remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "eval_ds = ds['validation'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "train_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca78a0b",
   "metadata": {},
   "source": [
    "Create the transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36846278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from transformers.models.bert.modeling_bert import BertModel, BertPreTrainedModel\n",
    "\n",
    "# https://github.com/huggingface/transformers/blob/65659a29cf5a079842e61a63d57fa24474288998/src/transformers/models/bert/modeling_bert.py#L1486\n",
    "\n",
    "class BertForSequenceClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs,\n",
    "        )\n",
    "        cls_outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        cls_outputs = self.dropout(cls_outputs)\n",
    "        logits = self.classifier(cls_outputs)\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b15ac966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    transformer_name,\n",
    "    num_labels=len(labels),\n",
    ")\n",
    "\n",
    "model = (\n",
    "    BertForSequenceClassification\n",
    "    .from_pretrained(transformer_name, config=config)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae1a93c",
   "metadata": {},
   "source": [
    "Create the trainer object and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d805f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 24\n",
    "weight_decay = 0.01\n",
    "model_name = f'{transformer_name}-sequence-classification'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name,\n",
    "    log_level='error',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy='epoch',\n",
    "    weight_decay=weight_decay,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a0699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_true = eval_pred.label_ids\n",
    "    y_pred = np.argmax(eval_pred.predictions, axis=-1)\n",
    "    return {'accuracy': accuracy_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c16ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=eval_ds,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301aefd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/miniconda3/envs/book/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9000' max='9000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9000/9000 28:48, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.172629</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.104000</td>\n",
       "      <td>0.183001</td>\n",
       "      <td>0.946250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9000, training_loss=0.1725272691514757, metrics={'train_runtime': 1728.9006, 'train_samples_per_second': 124.935, 'train_steps_per_second': 5.206, 'total_flos': 1.3104497872417536e+16, 'train_loss': 0.1725272691514757, 'epoch': 2.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1ec029",
   "metadata": {},
   "source": [
    "Evaluate on the test partition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa4b892f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c02b4652ee45278b2a36db48c5221d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 11284, 1116, 1111, 157, 151, 12966, 1170...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 1109, 6398, 1110, 1212, 131, 2307, 7219,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 148, 1183, 119, 1881, 16387, 1116, 4468,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 11689, 15906, 6115, 12056, 1116, 1370, 2...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>[101, 11917, 8914, 119, 19294, 4206, 1106, 215...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7595</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 5596, 1103, 1362, 5284, 5200, 3234, 1384...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 159, 7874, 1110, 2709, 1114, 13875, 1556...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7597</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 16247, 2972, 9178, 2409, 4271, 140, 1418...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 126, 1104, 1893, 8167, 10721, 4420, 1107...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7599</th>\n",
       "      <td>2</td>\n",
       "      <td>[101, 142, 2064, 4164, 3370, 1154, 13519, 1116...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          input_ids  \\\n",
       "0         2  [101, 11284, 1116, 1111, 157, 151, 12966, 1170...   \n",
       "1         3  [101, 1109, 6398, 1110, 1212, 131, 2307, 7219,...   \n",
       "2         3  [101, 148, 1183, 119, 1881, 16387, 1116, 4468,...   \n",
       "3         3  [101, 11689, 15906, 6115, 12056, 1116, 1370, 2...   \n",
       "4         3  [101, 11917, 8914, 119, 19294, 4206, 1106, 215...   \n",
       "...     ...                                                ...   \n",
       "7595      0  [101, 5596, 1103, 1362, 5284, 5200, 3234, 1384...   \n",
       "7596      1  [101, 159, 7874, 1110, 2709, 1114, 13875, 1556...   \n",
       "7597      1  [101, 16247, 2972, 9178, 2409, 4271, 140, 1418...   \n",
       "7598      2  [101, 126, 1104, 1893, 8167, 10721, 4420, 1107...   \n",
       "7599      2  [101, 142, 2064, 4164, 3370, 1154, 13519, 1116...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "7595  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7596  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7597  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7598  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7599  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "7595  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7596  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7597  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7598  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "7599  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[7600 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds = ds['test'].map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    remove_columns=['title', 'description', 'text'],\n",
    ")\n",
    "test_ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fe018fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='317' max='317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [317/317 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.19805276, -4.599117  ,  5.16667   , -1.7040474 ],\n",
       "       [-0.5993195 , -3.725446  , -2.9767706 ,  6.4002824 ],\n",
       "       [-0.68882525, -3.3542264 , -3.018547  ,  6.3239975 ],\n",
       "       ...,\n",
       "       [-0.5959751 ,  7.818701  , -2.3375113 , -3.3820465 ],\n",
       "       [ 0.3165054 , -2.9131033 ,  4.2329025 , -2.6117535 ],\n",
       "       [-3.012554  , -5.0199986 ,  4.2176995 ,  1.5888603 ]],\n",
       "      dtype=float32), label_ids=array([2, 3, 3, ..., 1, 2, 2]), metrics={'test_loss': 0.19474367797374725, 'test_accuracy': 0.9468421052631579, 'test_runtime': 17.4658, 'test_samples_per_second': 435.137, 'test_steps_per_second': 18.15})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = trainer.predict(test_ds)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14221494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       World       0.96      0.95      0.96      1900\n",
      "      Sports       0.99      0.99      0.99      1900\n",
      "    Business       0.93      0.91      0.92      1900\n",
      "    Sci/Tech       0.91      0.94      0.92      1900\n",
      "\n",
      "    accuracy                           0.95      7600\n",
      "   macro avg       0.95      0.95      0.95      7600\n",
      "weighted avg       0.95      0.95      0.95      7600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = output.label_ids\n",
    "y_pred = np.argmax(output.predictions, axis=-1)\n",
    "target_names = labels\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
