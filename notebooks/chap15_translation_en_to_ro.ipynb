{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b2596f8",
   "metadata": {},
   "source": [
    "# Machine Translation from English (En) to Romanian (Ro) \n",
    "# Using the T5 Transformer without Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f98399b",
   "metadata": {},
   "source": [
    "Some initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaef840c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 42\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import set_seed\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 42\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e83cf191",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_name = 't5-small'\n",
    "source_lang = 'en'\n",
    "target_lang = 'ro'\n",
    "max_source_length = 1024\n",
    "max_target_length = 128\n",
    "task_prefix = 'translate English to Romanian: '\n",
    "num_beams = 1\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b21365",
   "metadata": {},
   "source": [
    "Load tokenizer and pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27a06822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(transformer_name)\n",
    "\n",
    "# transformers.Trainer moves the model and data to the GPU automatically,\n",
    "# but since we won't use it in this notebook, we have to do it manually\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea53db",
   "metadata": {},
   "source": [
    "Load dataset from HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd678729",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/marco/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['translation'],\n",
       "    num_rows: 1999\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "test_ds = load_dataset('wmt16', 'ro-en', split='test')\n",
    "test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29548a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'UN Chief Says There Is No Military Solution in Syria',\n",
       " 'ro': 'Șeful ONU declară că nu există soluții militare în Siria'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds['translation'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2394d5",
   "metadata": {},
   "source": [
    "Implement the `translate` method and apply on this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03015a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(batch):\n",
    "    # get source language examples and prepend task prefix\n",
    "    inputs = [x[source_lang] for x in batch[\"translation\"]]\n",
    "    inputs = [task_prefix + x for x in inputs]\n",
    "    \n",
    "    # tokenize inputs\n",
    "    encoded = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_source_length,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    # move data to gpu if needed\n",
    "    input_ids = encoded.input_ids.to(device)\n",
    "    attention_mask = encoded.attention_mask.to(device)\n",
    "    \n",
    "    # generate translated sentences\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        num_beams=num_beams,\n",
    "        max_length=max_target_length,\n",
    "    )\n",
    "    \n",
    "    # generate predicted sentences from predicted token ids\n",
    "    decoded = tokenizer.batch_decode(\n",
    "        output,\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "    \n",
    "    # get gold sentences in target language\n",
    "    targets = [x[target_lang] for x in batch[\"translation\"]]\n",
    "    \n",
    "    # return gold and predicted sentences\n",
    "    return {\n",
    "        'reference': targets,\n",
    "        'prediction': decoded,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e9bd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fd196021a27431cb9b95603812da692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Șeful ONU declară că nu există soluții militar...</td>\n",
       "      <td>eful ONU declară că nu există o soluţie milita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Secretarul General Ban Ki-moon afirmă că răspu...</td>\n",
       "      <td>Secretarul General Ban Ki-moon declară că răsp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Șeful ONU a solicitat din nou tuturor părților...</td>\n",
       "      <td>eful U.N. a cerut din nou tuturor partidelor, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ban a declarat miercuri în cadrul unei conferi...</td>\n",
       "      <td>Ban a declarat la o conferinţă de presă susţin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ban și-a exprimat regretul că divizările în co...</td>\n",
       "      <td>El şi-a exprimat regretul că diviziunile din c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Nu sunt bani puțini.</td>\n",
       "      <td>Banii sunt suficienţi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Uneori mi-e rușine să ridic banii de la casierie.</td>\n",
       "      <td>Uneori mi-e ruşine să iau banii de la biroul c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>La sfârșitul mandatului voi face un raport cu ...</td>\n",
       "      <td>La sfârşitul biroului voi raporta tot ceea ce ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>S-a întâmplat să ridic într-o lună și 30.000 d...</td>\n",
       "      <td>Într-o lună am adunat 30 000 de lei cu ramburs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>\"Să spună un parlamentar că nu-i ajung banii e...</td>\n",
       "      <td>\"A spune că un parlamentar nu are suficienţi b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reference  \\\n",
       "0     Șeful ONU declară că nu există soluții militar...   \n",
       "1     Secretarul General Ban Ki-moon afirmă că răspu...   \n",
       "2     Șeful ONU a solicitat din nou tuturor părților...   \n",
       "3     Ban a declarat miercuri în cadrul unei conferi...   \n",
       "4     Ban și-a exprimat regretul că divizările în co...   \n",
       "...                                                 ...   \n",
       "1994                               Nu sunt bani puțini.   \n",
       "1995  Uneori mi-e rușine să ridic banii de la casierie.   \n",
       "1996  La sfârșitul mandatului voi face un raport cu ...   \n",
       "1997  S-a întâmplat să ridic într-o lună și 30.000 d...   \n",
       "1998  \"Să spună un parlamentar că nu-i ajung banii e...   \n",
       "\n",
       "                                             prediction  \n",
       "0     eful ONU declară că nu există o soluţie milita...  \n",
       "1     Secretarul General Ban Ki-moon declară că răsp...  \n",
       "2     eful U.N. a cerut din nou tuturor partidelor, ...  \n",
       "3     Ban a declarat la o conferinţă de presă susţin...  \n",
       "4     El şi-a exprimat regretul că diviziunile din c...  \n",
       "...                                                 ...  \n",
       "1994                             Banii sunt suficienţi.  \n",
       "1995  Uneori mi-e ruşine să iau banii de la biroul c...  \n",
       "1996  La sfârşitul biroului voi raporta tot ceea ce ...  \n",
       "1997  Într-o lună am adunat 30 000 de lei cu ramburs...  \n",
       "1998  \"A spune că un parlamentar nu are suficienţi b...  \n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = test_ds.map(\n",
    "    translate,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=test_ds.column_names,\n",
    ")\n",
    "\n",
    "results.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa9f70",
   "metadata": {},
   "source": [
    "Now evaluate the quality of translations using the BLEU metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144210bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 25.18405390123436,\n",
       " 'counts': [27521, 14902, 8681, 5141],\n",
       " 'totals': [49236, 47237, 45240, 43245],\n",
       " 'precisions': [55.89609229019417,\n",
       "  31.547304020153693,\n",
       "  19.188770999115828,\n",
       "  11.888079546768413],\n",
       " 'bp': 1.0,\n",
       " 'sys_len': 49236,\n",
       " 'ref_len': 48945}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "metric = load('sacrebleu')\n",
    "\n",
    "for r in results:\n",
    "    prediction = r['prediction']\n",
    "    reference = [r['reference']]\n",
    "    metric.add(prediction=prediction, reference=reference)\n",
    "    \n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd512e",
   "metadata": {},
   "source": [
    "An example of greedy decoding for individual texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e27413a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_translation(text):\n",
    "    # prepend task prefix\n",
    "    text = task_prefix + text\n",
    "    \n",
    "    # tokenize input\n",
    "    encoded = tokenizer(\n",
    "        text,\n",
    "        max_length=max_source_length,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    \n",
    "    # encoder input ids\n",
    "    encoder_input_ids = encoded.input_ids.to(device)\n",
    "    \n",
    "    # decoder input ids, initialized with start token id\n",
    "    start = model.config.decoder_start_token_id\n",
    "    decoder_input_ids = torch.LongTensor([[start]]).to(device)\n",
    "    \n",
    "    # generate tokens, one at a time\n",
    "    for _ in range(max_target_length):\n",
    "        # get model predictions\n",
    "        output = model(\n",
    "            encoder_input_ids,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "        )\n",
    "        # get logits for last token\n",
    "        next_token_logits = output.logits[0, -1, :]\n",
    "        # select most probable token\n",
    "        next_token_id = torch.argmax(next_token_logits)\n",
    "        # append new token to decoder_input_ids\n",
    "        output_id = torch.LongTensor([[next_token_id]]).to(device)\n",
    "        decoder_input_ids = torch.cat([decoder_input_ids, output_id], dim=-1)\n",
    "        # if predicted token is the end of sequence, stop iterating\n",
    "        if next_token_id == tokenizer.eos_token_id:\n",
    "            break\n",
    "            \n",
    "    # return text corresponding to predicted token ids\n",
    "    return tokenizer.decode(decoder_input_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7496a919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Acesta este un test'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_translation(\"this is a test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
